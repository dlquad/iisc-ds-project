{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75144f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Text processing and NLP libraries\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "import textstat\n",
    "\n",
    "# Set up plotting parameters\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "\n",
    "# Load the data (assuming df is already loaded from data collection notebook)\n",
    "df = pd.read_csv(\"../data/combined_final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306fed8c",
   "metadata": {},
   "source": [
    "**Getting Missing Value Info and Visualize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f9e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Data Frame Info about Missing Values\n",
    "\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing_values.index,\n",
    "    'Missing_Count': missing_values.values,\n",
    "    'Missing_Percentage': missing_percentage.values\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5186a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Missing values heatmap\n",
    "sns.heatmap(df.isnull(), cbar=True, yticklabels=False, cmap='viridis', ax=axes[0])\n",
    "axes[0].set_title('Missing Values Heatmap', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Missing values bar chart\n",
    "missing_df.plot(x='Column', y='Missing_Percentage', kind='bar', ax=axes[1], color='coral')\n",
    "axes[1].set_title('Missing Values Percentage by Column', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Missing Percentage (%)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73499c7e",
   "metadata": {},
   "source": [
    "**Calculating length of all texts and creating new features and visualize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6a55af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate text lengths and create new features\n",
    "df['title_length'] = df['title'].astype(str).str.len()\n",
    "df['text_length'] = df['text'].astype(str).str.len()\n",
    "df['title_word_count'] = df['title'].astype(str).str.split().str.len()\n",
    "df['text_word_count'] = df['text'].astype(str).str.split().str.len()\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Title length distribution\n",
    "axes[0,0].hist(df['title_length'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].set_title('Distribution of Title Length (Characters)', fontweight='bold')\n",
    "axes[0,0].set_xlabel('Title Length')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "\n",
    "# Text length distribution\n",
    "axes[0,1].hist(df['text_length'], bins=50, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[0,1].set_title('Distribution of Text Length (Characters)', fontweight='bold')\n",
    "axes[0,1].set_xlabel('Text Length')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "\n",
    "# Title word count distribution\n",
    "axes[1,0].hist(df['title_word_count'], bins=30, alpha=0.7, color='coral', edgecolor='black')\n",
    "axes[1,0].set_title('Distribution of Title Word Count', fontweight='bold')\n",
    "axes[1,0].set_xlabel('Word Count')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "\n",
    "# Text word count distribution\n",
    "axes[1,1].hist(df['text_word_count'], bins=50, alpha=0.7, color='plum', edgecolor='black')\n",
    "axes[1,1].set_title('Distribution of Text Word Count', fontweight='bold')\n",
    "axes[1,1].set_xlabel('Word Count')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a2bde4",
   "metadata": {},
   "source": [
    "**Generating Word Cloud for fake news and real news**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d45ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Word Cloud\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "fake_text = \" \".join(df[df[\"label\"]==0][\"text\"].astype(str).tolist())\n",
    "real_text = \" \".join(df[df[\"label\"]==1][\"text\"].astype(str).tolist())\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "wc_fake = WordCloud(width=600, height=400, background_color=\"black\").generate(fake_text)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(wc_fake, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake News Word Cloud\", fontsize=14)\n",
    "\n",
    "wc_real = WordCloud(width=600, height=400, background_color=\"white\").generate(real_text)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(wc_real, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real News Word Cloud\", fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312255f2",
   "metadata": {},
   "source": [
    "**Getting Average length Stats and generating visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57806e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average length stats\n",
    "stats = df.groupby(\"label\")[[\"text_length\", \"title_length\"]].mean()\n",
    "print(\"\\nAverage Length Stats by Label:\\n\", stats)\n",
    "\n",
    "# Create a figure with 3 subplots in one row\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "# Plot 1: Average Text Length per Label\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.barplot(x=stats.index, y=stats[\"text_length\"], hue=stats.index, palette=\"Set2\", legend=False)\n",
    "plt.title(\"Average Text Length per Label\")\n",
    "plt.xticks([0, 1], [\"Fake\", \"Real\"])\n",
    "plt.ylabel(\"Avg Text Length\")\n",
    "\n",
    "# Plot 2: Correlation Heatmap\n",
    "plt.subplot(1, 3, 2)\n",
    "corr_data = df[[\"text_length\", \"title_length\", \"label\"]].corr()\n",
    "sns.heatmap(corr_data, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "\n",
    "# Plot 3: Label Distribution\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.countplot(x='label', data=df, hue='label', palette='coolwarm', legend=False)\n",
    "plt.title(\"Fake (0) vs Real (1) Distribution\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks([0, 1], [\"Fake (0)\", \"Real (1)\"])\n",
    "\n",
    "# Adjust layout and show all 3 side by side\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e6b385",
   "metadata": {},
   "source": [
    "**Compare text Length distribution by label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fcf25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare text length distributions by label (if label column exists)\n",
    "if 'label' in df.columns:\n",
    "    print(\"COMPARING TEXT LENGTHS BY NEWS TYPE\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Create box plots for text length comparison\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    # Title length by label\n",
    "    df.boxplot(column='title_length', by='label', ax=axes[0,0])\n",
    "    axes[0,0].set_title('Title Length Distribution by News Type')\n",
    "    axes[0,0].set_xlabel('News Type')\n",
    "    axes[0,0].set_ylabel('Title Length (Characters)')\n",
    "\n",
    "    # Text length by label\n",
    "    df.boxplot(column='text_length', by='label', ax=axes[0,1])\n",
    "    axes[0,1].set_title('Text Length Distribution by News Type')\n",
    "    axes[0,1].set_xlabel('News Type')\n",
    "    axes[0,1].set_ylabel('Text Length (Characters)')\n",
    "\n",
    "    # Title word count by label\n",
    "    df.boxplot(column='title_word_count', by='label', ax=axes[1,0])\n",
    "    axes[1,0].set_title('Title Word Count by News Type')\n",
    "    axes[1,0].set_xlabel('News Type')\n",
    "    axes[1,0].set_ylabel('Word Count')\n",
    "\n",
    "    # Text word count by label\n",
    "    df.boxplot(column='text_word_count', by='label', ax=axes[1,1])\n",
    "    axes[1,1].set_title('Text Word Count by News Type')\n",
    "    axes[1,1].set_xlabel('News Type')\n",
    "    axes[1,1].set_ylabel('Word Count')\n",
    "\n",
    "    plt.suptitle('')  # Remove the automatic title\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Statistical comparison\n",
    "    print(\"\\nSTATISTICAL COMPARISON BY LABEL:\")\n",
    "    print(\"-\" * 40)\n",
    "    for label in df['label'].unique():\n",
    "        print(f\"\\n{label} News:\")\n",
    "        subset = df[df['label'] == label]\n",
    "        print(f\"Average title length: {subset['title_length'].mean():.1f} characters\")\n",
    "        print(f\"Average text length: {subset['text_length'].mean():.1f} characters\")\n",
    "        print(f\"Average title words: {subset['title_word_count'].mean():.1f} words\")\n",
    "        print(f\"Average text words: {subset['text_word_count'].mean():.1f} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b3a1e1",
   "metadata": {},
   "source": [
    "**Label Distribution and Class balance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0e1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze label distribution\n",
    "if 'label' in df.columns:\n",
    "    print(\"LABEL DISTRIBUTION ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Count and percentage distribution\n",
    "    label_counts = df['label'].value_counts()\n",
    "    label_percentages = df['label'].value_counts(normalize=True) * 100\n",
    "\n",
    "    print(\"Label Distribution:\")\n",
    "    print(\"-\" * 30)\n",
    "    for label in label_counts.index:\n",
    "        print(f\"{label}: {label_counts[label]:,} ({label_percentages[label]:.2f}%)\")\n",
    "\n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    # Pie chart\n",
    "    axes[0].pie(label_counts.values, labels=label_counts.index, autopct='%1.1f%%',\n",
    "                startangle=90)\n",
    "    axes[0].set_title('News Type Distributio', fontweight='bold')\n",
    "\n",
    "    # Bar chart\n",
    "    label_counts.plot(kind='bar', ax=axes[1], color=['coral', 'skyblue'])\n",
    "    axes[1].set_title('News Type Distribution', fontweight='bold')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Horizontal bar chart with percentages\n",
    "    axes[2].barh(range(len(label_percentages)), label_percentages.values,\n",
    "                 color=['lightgreen', 'lightcoral'])\n",
    "    axes[2].set_yticks(range(len(label_percentages)))\n",
    "    axes[2].set_yticklabels(label_percentages.index)\n",
    "    axes[2].set_xlabel('Percentage (%)')\n",
    "    axes[2].set_title('News Type Distribution', fontweight='bold')\n",
    "\n",
    "    # Add percentage labels on bars\n",
    "    for i, v in enumerate(label_percentages.values):\n",
    "        axes[2].text(v + 0.5, i, f'{v:.1f}%', va='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Class balance analysis\n",
    "    print(f\"\\nCLASS BALANCE ANALYSIS:\")\n",
    "    print(\"-\" * 30)\n",
    "    minority_class = label_counts.min()\n",
    "    majority_class = label_counts.max()\n",
    "    imbalance_ratio = majority_class / minority_class\n",
    "\n",
    "    print(f\"Minority class size: {minority_class:,}\")\n",
    "    print(f\"Majority class size: {majority_class:,}\")\n",
    "    print(f\"Imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "    if imbalance_ratio > 1.5:\n",
    "        print(\"Dataset shows class imbalance - consider sampling techniques\")\n",
    "    else:\n",
    "        print(\"Dataset is relatively balanced\")\n",
    "\n",
    "else:\n",
    "    print(\"No 'label' column found in the dataset\")\n",
    "    print(\"Available columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8848fe70",
   "metadata": {},
   "source": [
    "**Word Frequency Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408955ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare text for analysis\n",
    "def preprocess_text_basic(text):\n",
    "    \"\"\"Basic text preprocessing for word frequency analysis\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    # Convert to lowercase and remove special characters\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Tokenize and remove stopwords\n",
    "    try:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = word_tokenize(text)\n",
    "        words = [word for word in words if word not in stop_words and len(word) > 2]\n",
    "        return ' '.join(words)\n",
    "    except:\n",
    "        # If NLTK data not available, do basic processing\n",
    "        words = text.split()\n",
    "        common_stopwords = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'can', 'this', 'that', 'these', 'those'}\n",
    "        words = [word for word in words if word not in common_stopwords and len(word) > 2]\n",
    "        return ' '.join(words)\n",
    "\n",
    "print(\"WORD FREQUENCY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Preprocess text data\n",
    "print(\"Preprocessing text data...\")\n",
    "df['title_clean'] = df['title'].apply(preprocess_text_basic)\n",
    "df['text_clean'] = df['text'].apply(preprocess_text_basic)\n",
    "\n",
    "# Combine all text for overall analysis\n",
    "all_text = ' '.join(df['text_clean'].fillna('') + ' ' + df['title_clean'].fillna(''))\n",
    "all_words = all_text.split()\n",
    "\n",
    "# Get word frequency\n",
    "word_freq = Counter(all_words)\n",
    "most_common_words = word_freq.most_common(20)\n",
    "\n",
    "print(f\"Total unique words: {len(word_freq):,}\")\n",
    "print(f\"Total words: {len(all_words):,}\")\n",
    "\n",
    "# Create word frequency visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Top 20 most common words\n",
    "words, counts = zip(*most_common_words)\n",
    "axes[0].barh(range(len(words)), counts, color='lightblue')\n",
    "axes[0].set_yticks(range(len(words)))\n",
    "axes[0].set_yticklabels(words)\n",
    "axes[0].set_xlabel('Frequency')\n",
    "axes[0].set_title('Top 20 Most Common Words', fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Word cloud\n",
    "if len(all_text) > 0:\n",
    "    try:\n",
    "        wordcloud = WordCloud(width=800, height=400, background_color='white',\n",
    "                             max_words=100, colormap='viridis').generate(all_text)\n",
    "        axes[1].imshow(wordcloud, interpolation='bilinear')\n",
    "        axes[1].axis('off')\n",
    "        axes[1].set_title('Word Cloud - All News Articles', fontweight='bold')\n",
    "    except Exception as e:\n",
    "        axes[1].text(0.5, 0.5, f'Word cloud generation failed:\\n{str(e)}',\n",
    "                    ha='center', va='center', transform=axes[1].transAxes)\n",
    "        axes[1].set_title('Word Cloud - Generation Failed', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTOP 20 MOST COMMON WORDS:\")\n",
    "print(\"-\" * 30)\n",
    "for i, (word, count) in enumerate(most_common_words, 1):\n",
    "    print(f\"{i:2d}. {word:15} : {count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f160fc25",
   "metadata": {},
   "source": [
    "## N-gram Analysis (Unigrams, Bigrams, Trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6ff71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-gram analysis functions\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_ngrams(text, n):\n",
    "    \"\"\"Extract n-grams from text\"\"\"\n",
    "    words = text.split()\n",
    "    if len(words) < n:\n",
    "        return []\n",
    "    return [' '.join(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "\n",
    "def analyze_ngrams(text_series, n, top_k=15):\n",
    "    \"\"\"Analyze n-grams in a text series\"\"\"\n",
    "    all_ngrams = []\n",
    "    for text in text_series.fillna(''):\n",
    "        all_ngrams.extend(get_ngrams(text, n))\n",
    "\n",
    "    ngram_freq = Counter(all_ngrams)\n",
    "    return ngram_freq.most_common(top_k)\n",
    "\n",
    "print(\"N-GRAM ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Combine all processed text\n",
    "all_processed_text = df['text_processed'].fillna('') + ' ' + df['title_processed'].fillna('')\n",
    "\n",
    "# Analyze unigrams, bigrams, and trigrams\n",
    "unigrams = analyze_ngrams(all_processed_text, 1, 20)\n",
    "bigrams = analyze_ngrams(all_processed_text, 2, 15)\n",
    "trigrams = analyze_ngrams(all_processed_text, 3, 10)\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 16))\n",
    "\n",
    "# Unigrams\n",
    "if unigrams:\n",
    "    words, counts = zip(*unigrams)\n",
    "    axes[0].barh(range(len(words)), counts, color='lightblue')\n",
    "    axes[0].set_yticks(range(len(words)))\n",
    "    axes[0].set_yticklabels(words)\n",
    "    axes[0].set_xlabel('Frequency')\n",
    "    axes[0].set_title('Top 20 Unigrams (Single Words)', fontweight='bold', fontsize=14)\n",
    "    axes[0].invert_yaxis()\n",
    "\n",
    "# Bigrams\n",
    "if bigrams:\n",
    "    words, counts = zip(*bigrams)\n",
    "    axes[1].barh(range(len(words)), counts, color='lightgreen')\n",
    "    axes[1].set_yticks(range(len(words)))\n",
    "    axes[1].set_yticklabels(words)\n",
    "    axes[1].set_xlabel('Frequency')\n",
    "    axes[1].set_title('Top 15 Bigrams (Two-word Phrases)', fontweight='bold', fontsize=14)\n",
    "    axes[1].invert_yaxis()\n",
    "\n",
    "# Trigrams\n",
    "if trigrams:\n",
    "    words, counts = zip(*trigrams)\n",
    "    axes[2].barh(range(len(words)), counts, color='lightcoral')\n",
    "    axes[2].set_yticks(range(len(words)))\n",
    "    axes[2].set_yticklabels(words)\n",
    "    axes[2].set_xlabel('Frequency')\n",
    "    axes[2].set_title('Top 10 Trigrams (Three-word Phrases)', fontweight='bold', fontsize=14)\n",
    "    axes[2].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print results\n",
    "print(\"TOP UNIGRAMS:\")\n",
    "print(\"-\" * 30)\n",
    "for i, (gram, count) in enumerate(unigrams[:15], 1):\n",
    "    print(f\"{i:2d}. {gram:20} : {count:,}\")\n",
    "\n",
    "print(f\"\\nTOP BIGRAMS:\")\n",
    "print(\"-\" * 30)\n",
    "for i, (gram, count) in enumerate(bigrams[:10], 1):\n",
    "    print(f\"{i:2d}. {gram:30} : {count:,}\")\n",
    "\n",
    "print(f\"\\nTOP TRIGRAMS:\")\n",
    "print(\"-\" * 30)\n",
    "for i, (gram, count) in enumerate(trigrams[:10], 1):\n",
    "    print(f\"{i:2d}. {gram:40} : {count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97924c4c",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71eb12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis using TextBlob\n",
    "def get_sentiment_score(text):\n",
    "    \"\"\"Calculate sentiment polarity using TextBlob\"\"\"\n",
    "    if pd.isna(text) or text == \"\":\n",
    "        return 0\n",
    "    try:\n",
    "        blob = TextBlob(str(text))\n",
    "        return blob.sentiment.polarity\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def get_subjectivity_score(text):\n",
    "    \"\"\"Calculate subjectivity using TextBlob\"\"\"\n",
    "    if pd.isna(text) or text == \"\":\n",
    "        return 0\n",
    "    try:\n",
    "        blob = TextBlob(str(text))\n",
    "        return blob.sentiment.subjectivity\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def categorize_sentiment(score):\n",
    "    \"\"\"Categorize sentiment score\"\"\"\n",
    "    if score > 0.1:\n",
    "        return 'Positive'\n",
    "    elif score < -0.1:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "print(\"SENTIMENT ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate sentiment scores\n",
    "print(\"Calculating sentiment scores...\")\n",
    "df['title_sentiment'] = df['title'].apply(get_sentiment_score)\n",
    "df['text_sentiment'] = df['text'].apply(get_sentiment_score)\n",
    "df['title_subjectivity'] = df['title'].apply(get_subjectivity_score)\n",
    "df['text_subjectivity'] = df['text'].apply(get_subjectivity_score)\n",
    "\n",
    "# Categorize sentiments\n",
    "df['title_sentiment_category'] = df['title_sentiment'].apply(categorize_sentiment)\n",
    "df['text_sentiment_category'] = df['text_sentiment'].apply(categorize_sentiment)\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Sentiment score distributions\n",
    "axes[0,0].hist(df['title_sentiment'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].set_title('Title Sentiment Distribution', fontweight='bold')\n",
    "axes[0,0].set_xlabel('Sentiment Score (-1 to 1)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].axvline(x=0, color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "axes[0,1].hist(df['text_sentiment'], bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[0,1].set_title('Text Sentiment Distribution', fontweight='bold')\n",
    "axes[0,1].set_xlabel('Sentiment Score (-1 to 1)')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "axes[0,1].axvline(x=0, color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Subjectivity distributions\n",
    "axes[0,2].hist(df['text_subjectivity'], bins=30, alpha=0.7, color='coral', edgecolor='black')\n",
    "axes[0,2].set_title('Text Subjectivity Distribution', fontweight='bold')\n",
    "axes[0,2].set_xlabel('Subjectivity Score (0 to 1)')\n",
    "axes[0,2].set_ylabel('Frequency')\n",
    "\n",
    "# Sentiment categories\n",
    "title_sent_counts = df['title_sentiment_category'].value_counts()\n",
    "axes[1,0].pie(title_sent_counts.values, labels=title_sent_counts.index, autopct='%1.1f%%',\n",
    "              colors=['lightblue', 'lightcoral', 'lightgreen'])\n",
    "axes[1,0].set_title('Title Sentiment Categories', fontweight='bold')\n",
    "\n",
    "text_sent_counts = df['text_sentiment_category'].value_counts()\n",
    "axes[1,1].pie(text_sent_counts.values, labels=text_sent_counts.index, autopct='%1.1f%%',\n",
    "              colors=['lightblue', 'lightcoral', 'lightgreen'])\n",
    "axes[1,1].set_title('Text Sentiment Categories', fontweight='bold')\n",
    "\n",
    "# Sentiment vs Subjectivity scatter plot\n",
    "scatter = axes[1,2].scatter(df['text_sentiment'], df['text_subjectivity'],\n",
    "                           alpha=0.5, c=df['text_sentiment'], cmap='RdYlBu', s=10)\n",
    "axes[1,2].set_xlabel('Sentiment Score')\n",
    "axes[1,2].set_ylabel('Subjectivity Score')\n",
    "axes[1,2].set_title('Sentiment vs Subjectivity', fontweight='bold')\n",
    "plt.colorbar(scatter, ax=axes[1,2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print sentiment statistics\n",
    "print(\"SENTIMENT ANALYSIS STATISTICS:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Title Sentiment - Mean: {df['title_sentiment'].mean():.3f}, Std: {df['title_sentiment'].std():.3f}\")\n",
    "print(f\"Text Sentiment - Mean: {df['text_sentiment'].mean():.3f}, Std: {df['text_sentiment'].std():.3f}\")\n",
    "print(f\"Text Subjectivity - Mean: {df['text_subjectivity'].mean():.3f}, Std: {df['text_subjectivity'].std():.3f}\")\n",
    "\n",
    "print(f\"\\nTITLE SENTIMENT CATEGORIES:\")\n",
    "print(title_sent_counts)\n",
    "\n",
    "print(f\"\\nTEXT SENTIMENT CATEGORIES:\")\n",
    "print(text_sent_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c45a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare sentiment between fake and real news (if label exists)\n",
    "if 'label' in df.columns:\n",
    "    print(\"SENTIMENT COMPARISON BY NEWS TYPE\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "    # Box plots for sentiment comparison\n",
    "    df.boxplot(column='title_sentiment', by='label', ax=axes[0,0])\n",
    "    axes[0,0].set_title('Title Sentiment by News Type')\n",
    "    axes[0,0].set_xlabel('News Type')\n",
    "    axes[0,0].set_ylabel('Sentiment Score')\n",
    "\n",
    "    df.boxplot(column='text_sentiment', by='label', ax=axes[0,1])\n",
    "    axes[0,1].set_title('Text Sentiment by News Type')\n",
    "    axes[0,1].set_xlabel('News Type')\n",
    "    axes[0,1].set_ylabel('Sentiment Score')\n",
    "\n",
    "    df.boxplot(column='text_subjectivity', by='label', ax=axes[1,0])\n",
    "    axes[1,0].set_title('Text Subjectivity by News Type')\n",
    "    axes[1,0].set_xlabel('News Type')\n",
    "    axes[1,0].set_ylabel('Subjectivity Score')\n",
    "\n",
    "    # Sentiment category comparison\n",
    "    sentiment_cross = pd.crosstab(df['label'], df['text_sentiment_category'])\n",
    "    sentiment_cross_pct = pd.crosstab(df['label'], df['text_sentiment_category'], normalize='index') * 100\n",
    "\n",
    "    sentiment_cross_pct.plot(kind='bar', ax=axes[1,1], color=['lightcoral', 'lightgray', 'lightgreen'])\n",
    "    axes[1,1].set_title('Sentiment Categories by News Type (%)')\n",
    "    axes[1,1].set_xlabel('News Type')\n",
    "    axes[1,1].set_ylabel('Percentage')\n",
    "    axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    axes[1,1].legend(title='Sentiment')\n",
    "\n",
    "    plt.suptitle('')  # Remove automatic title\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Statistical comparison\n",
    "    print(\"SENTIMENT STATISTICS BY LABEL:\")\n",
    "    print(\"-\" * 40)\n",
    "    for label in df['label'].unique():\n",
    "        subset = df[df['label'] == label]\n",
    "        print(f\"\\n{label} News:\")\n",
    "        print(f\"  Title sentiment - Mean: {subset['title_sentiment'].mean():.3f}\")\n",
    "        print(f\"  Text sentiment - Mean: {subset['text_sentiment'].mean():.3f}\")\n",
    "        print(f\"  Text subjectivity - Mean: {subset['text_subjectivity'].mean():.3f}\")\n",
    "\n",
    "        print(f\"  Sentiment categories:\")\n",
    "        categories = subset['text_sentiment_category'].value_counts()\n",
    "        for cat, count in categories.items():\n",
    "            pct = (count / len(subset)) * 100\n",
    "            print(f\"    {cat}: {count:,} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b34c22c",
   "metadata": {},
   "source": [
    "## Text Complexity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc8e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate text complexity metrics\n",
    "def safe_textstat_metric(text, metric_func, default_value=0):\n",
    "    \"\"\"Safely calculate textstat metrics with error handling\"\"\"\n",
    "    try:\n",
    "        if pd.isna(text) or text == \"\":\n",
    "            return default_value\n",
    "        return metric_func(str(text))\n",
    "    except:\n",
    "        return default_value\n",
    "\n",
    "def calculate_complexity_metrics(text):\n",
    "    \"\"\"Calculate various text complexity metrics\"\"\"\n",
    "    if pd.isna(text) or text == \"\":\n",
    "        return {\n",
    "            'readability_score': 0,\n",
    "            'avg_sentence_length': 0,\n",
    "            'syllable_count': 0,\n",
    "            'flesch_kincaid_grade': 0,\n",
    "            'sentence_count': 0\n",
    "        }\n",
    "\n",
    "    text_str = str(text)\n",
    "\n",
    "    try:\n",
    "        # Use textstat if available\n",
    "        readability = safe_textstat_metric(text_str, textstat.flesch_reading_ease, 0)\n",
    "        fk_grade = safe_textstat_metric(text_str, textstat.flesch_kincaid_grade, 0)\n",
    "        syllables = safe_textstat_metric(text_str, textstat.syllable_count, 0)\n",
    "        sentences = safe_textstat_metric(text_str, textstat.sentence_count, 1)\n",
    "\n",
    "        # Calculate average sentence length\n",
    "        words = len(text_str.split())\n",
    "        avg_sent_length = words / sentences if sentences > 0 else 0\n",
    "\n",
    "    except:\n",
    "        # Fallback calculations\n",
    "        sentences = text_str.count('.') + text_str.count('!') + text_str.count('?')\n",
    "        sentences = max(sentences, 1)\n",
    "        words = len(text_str.split())\n",
    "\n",
    "        readability = 50  # Default neutral score\n",
    "        fk_grade = 8     # Default grade level\n",
    "        syllables = words * 1.5  # Rough estimate\n",
    "        avg_sent_length = words / sentences\n",
    "\n",
    "    return {\n",
    "        'readability_score': readability,\n",
    "        'avg_sentence_length': avg_sent_length,\n",
    "        'syllable_count': syllables,\n",
    "        'flesch_kincaid_grade': fk_grade,\n",
    "        'sentence_count': sentences\n",
    "    }\n",
    "\n",
    "print(\"TEXT COMPLEXITY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"Calculating text complexity metrics...\")\n",
    "\n",
    "# Calculate complexity metrics for a sample (to avoid long processing time)\n",
    "sample_size = min(5000, len(df))\n",
    "sample_df = df.sample(n=sample_size, random_state=42).copy()\n",
    "\n",
    "# Calculate metrics\n",
    "complexity_results = sample_df['text'].apply(calculate_complexity_metrics)\n",
    "complexity_df = pd.DataFrame(complexity_results.tolist())\n",
    "\n",
    "# Add metrics to sample dataframe\n",
    "for col in complexity_df.columns:\n",
    "    sample_df[col] = complexity_df[col]\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Readability score distribution\n",
    "axes[0,0].hist(sample_df['readability_score'], bins=30, alpha=0.7, color='lightblue', edgecolor='black')\n",
    "axes[0,0].set_title('Flesch Reading Ease Score Distribution', fontweight='bold')\n",
    "axes[0,0].set_xlabel('Reading Ease Score (0-100)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].axvline(x=50, color='red', linestyle='--', alpha=0.7, label='Average')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# Average sentence length\n",
    "axes[0,1].hist(sample_df['avg_sentence_length'], bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[0,1].set_title('Average Sentence Length Distribution', fontweight='bold')\n",
    "axes[0,1].set_xlabel('Average Words per Sentence')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "\n",
    "# Flesch-Kincaid Grade Level\n",
    "axes[0,2].hist(sample_df['flesch_kincaid_grade'], bins=30, alpha=0.7, color='coral', edgecolor='black')\n",
    "axes[0,2].set_title('Flesch-Kincaid Grade Level Distribution', fontweight='bold')\n",
    "axes[0,2].set_xlabel('Grade Level')\n",
    "axes[0,2].set_ylabel('Frequency')\n",
    "\n",
    "# Syllable count distribution\n",
    "axes[1,0].hist(sample_df['syllable_count'], bins=30, alpha=0.7, color='plum', edgecolor='black')\n",
    "axes[1,0].set_title('Syllable Count Distribution', fontweight='bold')\n",
    "axes[1,0].set_xlabel('Number of Syllables')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "\n",
    "# Sentence count distribution\n",
    "axes[1,1].hist(sample_df['sentence_count'], bins=30, alpha=0.7, color='lightyellow', edgecolor='black')\n",
    "axes[1,1].set_title('Sentence Count Distribution', fontweight='bold')\n",
    "axes[1,1].set_xlabel('Number of Sentences')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "\n",
    "# Correlation heatmap of complexity metrics\n",
    "complexity_corr = sample_df[['readability_score', 'avg_sentence_length', 'syllable_count',\n",
    "                           'flesch_kincaid_grade', 'sentence_count']].corr()\n",
    "im = axes[1,2].imshow(complexity_corr, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "axes[1,2].set_title('Complexity Metrics Correlation', fontweight='bold')\n",
    "axes[1,2].set_xticks(range(len(complexity_corr.columns)))\n",
    "axes[1,2].set_yticks(range(len(complexity_corr.columns)))\n",
    "axes[1,2].set_xticklabels([col.replace('_', '\\n') for col in complexity_corr.columns], rotation=45)\n",
    "axes[1,2].set_yticklabels([col.replace('_', '\\n') for col in complexity_corr.columns])\n",
    "\n",
    "# Add correlation values to heatmap\n",
    "for i in range(len(complexity_corr.columns)):\n",
    "    for j in range(len(complexity_corr.columns)):\n",
    "        axes[1,2].text(j, i, f'{complexity_corr.iloc[i, j]:.2f}',\n",
    "                      ha='center', va='center', color='black' if abs(complexity_corr.iloc[i, j]) < 0.5 else 'white')\n",
    "\n",
    "plt.colorbar(im, ax=axes[1,2])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(f\"COMPLEXITY METRICS STATISTICS (Sample of {sample_size:,} articles):\")\n",
    "print(\"-\" * 60)\n",
    "complexity_stats = sample_df[['readability_score', 'avg_sentence_length', 'syllable_count',\n",
    "                            'flesch_kincaid_grade', 'sentence_count']].describe()\n",
    "print(complexity_stats)\n",
    "\n",
    "# Interpret readability scores\n",
    "print(f\"\\nREADABILITY INTERPRETATION:\")\n",
    "print(\"-\" * 30)\n",
    "mean_readability = sample_df['readability_score'].mean()\n",
    "if mean_readability >= 90:\n",
    "    level = \"Very Easy (5th grade)\"\n",
    "elif mean_readability >= 80:\n",
    "    level = \"Easy (6th grade)\"\n",
    "elif mean_readability >= 70:\n",
    "    level = \"Fairly Easy (7th grade)\"\n",
    "elif mean_readability >= 60:\n",
    "    level = \"Standard (8th-9th grade)\"\n",
    "elif mean_readability >= 50:\n",
    "    level = \"Fairly Difficult (10th-12th grade)\"\n",
    "elif mean_readability >= 30:\n",
    "    level = \"Difficult (college level)\"\n",
    "else:\n",
    "    level = \"Very Difficult (graduate level)\"\n",
    "\n",
    "print(f\"Average readability score: {mean_readability:.1f} ({level})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5a8893",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### Key Findings from EDA:\n",
    "\n",
    "1. **Dataset Overview**: The combined dataset contains news articles with text, titles, and labels for fake/real classification\n",
    "2. **Text Characteristics**: Analyzed length distributions, word counts, and complexity metrics\n",
    "3. **Label Distribution**: Examined class balance and potential imbalance issues\n",
    "4. **Language Patterns**: Identified distinctive words and phrases in fake vs real news\n",
    "5. **Sentiment Analysis**: Discovered sentiment patterns that may distinguish fake from real news\n",
    "6. **Feature Engineering**: Created new features based on text statistics, sentiment, and linguistic patterns\n",
    "\n",
    "### Recommendations for Machine Learning Model:\n",
    "\n",
    "1. **Data Preprocessing**:\n",
    "   - Handle missing values appropriately\n",
    "   - Apply text cleaning and normalization\n",
    "   - Consider sampling techniques if class imbalance exists\n",
    "\n",
    "2. **Feature Selection**:\n",
    "   - Use the engineered features showing high correlation with target\n",
    "   - Apply dimensionality reduction techniques if needed\n",
    "   - Consider TF-IDF or word embeddings for text features\n",
    "\n",
    "3. **Model Selection**:\n",
    "   - Start with baseline models (Logistic Regression, Naive Bayes)\n",
    "   - Try ensemble methods (Random Forest, XGBoost)\n",
    "   - Consider deep learning approaches (LSTM, BERT) for text classification\n",
    "\n",
    "4. **Evaluation**:\n",
    "   - Use appropriate metrics (accuracy, precision, recall, F1-score)\n",
    "   - Implement cross-validation for robust evaluation\n",
    "   - Monitor for overfitting\n",
    "\n",
    "5. **Real-time Deployment**:\n",
    "   - Design efficient preprocessing pipeline\n",
    "   - Optimize model for speed and memory usage\n",
    "   - Implement monitoring and retraining mechanisms\n",
    "\n",
    "**Next Step**: Begin building machine learning models using the insights and features from this analysis!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
