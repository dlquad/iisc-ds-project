{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd882ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af1c543",
   "metadata": {},
   "source": [
    "## Model Evaluation - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ebd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Confusion Matrix and ROC for Logistic Regression\n",
    "matrix = confusion_matrix(y_test, y_pred_lr, normalize='all')\n",
    "\n",
    "# Compute ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob_lr)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# --- Confusion Matrix ---\n",
    "sns.heatmap(matrix, annot=True, fmt=\".2f\", cmap=\"Blues\", ax=axes[0])\n",
    "axes[0].set_title(\"Confusion Matrix - Logistic Regression\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0].set_xlabel(\"Predicted Labels\", fontsize=12)\n",
    "axes[0].set_ylabel(\"True Labels\", fontsize=12)\n",
    "axes[0].xaxis.set_ticklabels([\"Fake\", \"Real\"], fontsize=11)\n",
    "axes[0].yaxis.set_ticklabels([\"Fake\", \"Real\"], fontsize=11)\n",
    "\n",
    "# --- ROC Curve ---\n",
    "axes[1].plot(fpr, tpr, color='darkorange', lw=2,\n",
    "             label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "axes[1].plot([0,1], [0,1], color='navy', linestyle='--', lw=1.5)\n",
    "axes[1].set_title(\"ROC Curve - Logistic Regression\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1].set_xlabel(\"False Positive Rate\", fontsize=12)\n",
    "axes[1].set_ylabel(\"True Positive Rate\", fontsize=12)\n",
    "axes[1].legend(loc=\"lower right\", fontsize=11)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2f22e1",
   "metadata": {},
   "source": [
    "## Model Evaluation - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1bc96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Confusion Matrix and ROC for XGBoost\n",
    "matrix = confusion_matrix(y_test, y_pred_xgb, normalize='all')\n",
    "\n",
    "# Compute ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob_xgb)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# --- Confusion Matrix ---\n",
    "sns.heatmap(matrix, annot=True, fmt=\".2f\", cmap=\"Blues\", ax=axes[0])\n",
    "axes[0].set_title(\"Confusion Matrix - XGBoost\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0].set_xlabel(\"Predicted Labels\", fontsize=12)\n",
    "axes[0].set_ylabel(\"True Labels\", fontsize=12)\n",
    "axes[0].xaxis.set_ticklabels([\"Fake\", \"Real\"], fontsize=11)\n",
    "axes[0].yaxis.set_ticklabels([\"Fake\", \"Real\"], fontsize=11)\n",
    "\n",
    "# --- ROC Curve ---\n",
    "axes[1].plot(fpr, tpr, color='darkorange', lw=2,\n",
    "             label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "axes[1].plot([0,1], [0,1], color='navy', linestyle='--', lw=1.5)\n",
    "axes[1].set_title(\"ROC Curve - XGBoost\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1].set_xlabel(\"False Positive Rate\", fontsize=12)\n",
    "axes[1].set_ylabel(\"True Positive Rate\", fontsize=12)\n",
    "axes[1].legend(loc=\"lower right\", fontsize=11)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43b32c8",
   "metadata": {},
   "source": [
    "## Model Evaluation - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26d9839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate LSTM model\n",
    "model_lstm.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50e015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with LSTM\n",
    "pred = model_lstm.predict(X_test)\n",
    "\n",
    "binary_predictions = []\n",
    "for i in pred:\n",
    "    if i >= 0.5:\n",
    "        binary_predictions.append(1)\n",
    "    else:\n",
    "        binary_predictions.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92ff10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for LSTM\n",
    "print('Accuracy on testing set:', accuracy_score(binary_predictions, y_test))\n",
    "print('Precision on testing set:', precision_score(binary_predictions, y_test))\n",
    "print('Recall on testing set:', recall_score(binary_predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6254c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Confusion Matrix and ROC for LSTM\n",
    "matrix = confusion_matrix(y_test, binary_predictions, normalize='all')\n",
    "\n",
    "# Compute ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, binary_predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# --- Confusion Matrix ---\n",
    "sns.heatmap(matrix, annot=True, fmt=\".2f\", cmap=\"Blues\", ax=axes[0])\n",
    "axes[0].set_title(\"Confusion Matrix - LSTM\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0].set_xlabel(\"Predicted Labels\", fontsize=12)\n",
    "axes[0].set_ylabel(\"True Labels\", fontsize=12)\n",
    "axes[0].xaxis.set_ticklabels([\"Fake\", \"Real\"], fontsize=11)\n",
    "axes[0].yaxis.set_ticklabels([\"Fake\", \"Real\"], fontsize=11)\n",
    "\n",
    "# --- ROC Curve ---\n",
    "axes[1].plot(fpr, tpr, color='darkorange', lw=2,\n",
    "             label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "axes[1].plot([0,1], [0,1], color='navy', linestyle='--', lw=1.5)\n",
    "axes[1].set_title(\"ROC Curve - LSTM\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1].set_xlabel(\"False Positive Rate\", fontsize=12)\n",
    "axes[1].set_ylabel(\"True Positive Rate\", fontsize=12)\n",
    "axes[1].legend(loc=\"lower right\", fontsize=11)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8fe205",
   "metadata": {},
   "source": [
    "## Model Comparison - Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be7f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all predictions have the same length\n",
    "print(\"y_test:\", len(y_test))\n",
    "print(\"y_pred_lr:\", len(y_pred_lr))\n",
    "print(\"y_pred_xgb:\", len(y_pred_xgb))\n",
    "print(\"binary_predictions (LSTM):\", len(binary_predictions))\n",
    "\n",
    "min_len = len(y_test)\n",
    "\n",
    "y_pred_lr = y_pred_lr[:min_len]\n",
    "y_pred_xgb = y_pred_xgb[:min_len]\n",
    "binary_predictions = binary_predictions[:min_len]\n",
    "\n",
    "y_pred_prob_lr = y_pred_prob_lr[:min_len]\n",
    "y_pred_prob_xgb = y_pred_prob_xgb[:min_len]\n",
    "y_pred_prob_lstm = binary_predictions[:min_len]  # sigmoid output before threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa68550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-recall curves\n",
    "lr_precision, lr_recall, _ = precision_recall_curve(y_test, y_pred_prob_lr)\n",
    "xgb_precision, xgb_recall, _ = precision_recall_curve(y_test, y_pred_prob_xgb)\n",
    "lstm_precision, lstm_recall, _ = precision_recall_curve(y_test, y_pred_prob_lstm)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(lr_recall, lr_precision, color='blue', label='Logistic Regression')\n",
    "plt.plot(xgb_recall, xgb_precision, color='red', label='XGBoost')\n",
    "plt.plot(lstm_recall, lstm_precision, color='green', label='LSTM')\n",
    "\n",
    "plt.xlabel('Recall', fontsize=12)\n",
    "plt.ylabel('Precision', fontsize=12)\n",
    "plt.title('Precision-Recall Curve (All Models)', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bda5c01",
   "metadata": {},
   "source": [
    "**The Moment of Truth:**\n",
    "\n",
    "* All three models (LR, XGB, LSTM) perform similarly in distinguishing fake vs. real news.\n",
    "* LSTM has excellent precision only at extremely low recall.\n",
    "* For general recall ranges, LR and XGB perform similarly and consistently.\n",
    "* Overall, these results indicate current models have limited separation power, and a transformer-based model (like BERT) is the logical next improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb0f9ba",
   "metadata": {},
   "source": [
    "## Deployment Setup - Streamlit UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2825b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for deployment\n",
    "!pip install streamlit\n",
    "!pip install tensorflow xgboost scikit-learn huggingface_hub joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ffc7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from huggingface_hub import hf_hub_download\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_LEN = 200\n",
    "REPO_ID = \"dl-quad/fake-news-bi-lstm-dl-quadrilateral\"\n",
    "\n",
    "KERAS_MODEL_FILE = \"lstm/fake_news_bi_lstm_model.keras\"\n",
    "KERAS_TOKENIZER_FILE = \"lstm/tokenizer.pkl\"\n",
    "\n",
    "# Load Model & Tokenizer\n",
    "@st.cache_resource\n",
    "def load_lstm_model():\n",
    "    keras_model_path = hf_hub_download(repo_id=REPO_ID, filename=KERAS_MODEL_FILE)\n",
    "    keras_tokenizer_path = hf_hub_download(repo_id=REPO_ID, filename=KERAS_TOKENIZER_FILE)\n",
    "\n",
    "    keras_model = tf.keras.models.load_model(keras_model_path)\n",
    "    keras_tokenizer = joblib.load(keras_tokenizer_path)\n",
    "\n",
    "    return keras_model, keras_tokenizer\n",
    "\n",
    "keras_model, keras_tokenizer = load_lstm_model()\n",
    "\n",
    "# Prediction Function\n",
    "def predict_with_lstm(text):\n",
    "    seq = keras_tokenizer.texts_to_sequences([text])\n",
    "    padded = pad_sequences(seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "    prob_raw = keras_model.predict(padded)[0][0]\n",
    "    prob_real = float(tf.nn.sigmoid(prob_raw).numpy())\n",
    "\n",
    "    return prob_real  # REAL probability\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"Fake News Detection – Bi-LSTM Model\")\n",
    "\n",
    "st.write(\"### Model Settings\")\n",
    "threshold = st.slider(\"Decision Threshold (Recommended: 0.40 – 0.50)\", 0.1, 0.9, 0.40)\n",
    "uncertainty_margin = st.slider(\"Uncertainty Range (+/-)\", 0.05, 0.30, 0.10)\n",
    "\n",
    "user_text = st.text_area(\"Enter news text for classification:\", height=200)\n",
    "\n",
    "if st.button(\"Predict\"):\n",
    "    if not user_text.strip():\n",
    "        st.warning(\"Please enter some text.\")\n",
    "    else:\n",
    "        prob_real = predict_with_lstm(user_text)\n",
    "        prob_fake = 1 - prob_real\n",
    "\n",
    "        lower_bound = threshold - uncertainty_margin\n",
    "        upper_bound = threshold + uncertainty_margin\n",
    "\n",
    "        st.subheader(\"Prediction Result\")\n",
    "\n",
    "        # Uncertain zone\n",
    "        if lower_bound <= prob_real <= upper_bound:\n",
    "            st.warning(\"**UNCERTAIN NEWS** — Model is not confident.\\nPlease verify with trusted sources.\")\n",
    "            st.write(f\"Real Confidence: {prob_real * 100:.2f}%\")\n",
    "            st.write(f\"Fake Confidence: {prob_fake * 100:.2f}%\")\n",
    "            st.progress(prob_real)\n",
    "\n",
    "        # Clear REAL\n",
    "        elif prob_real > upper_bound:\n",
    "            st.success(f\"Prediction: **REAL NEWS**\")\n",
    "            st.write(f\"Real Confidence: {prob_real * 100:.2f}%\")\n",
    "            st.progress(prob_real)\n",
    "\n",
    "        # Clear FAKE\n",
    "        else:\n",
    "            st.error(f\"Prediction: **FAKE NEWS**\")\n",
    "            st.write(f\"Fake Confidence: {prob_fake * 100:.2f}%\")\n",
    "            st.progress(prob_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41685b8",
   "metadata": {},
   "source": [
    "## Setup Deployment Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a3d712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install localtunnel for public URL\n",
    "!npm install -g localtunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e534de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install cloudflared for tunneling\n",
    "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
    "!sudo dpkg -i cloudflared-linux-amd64.deb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cf4727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Streamlit app with cloudflared tunnel\n",
    "!streamlit run app.py --server.port 8501 --server.address 0.0.0.0 & sleep 2 && cloudflared tunnel --url http://localhost:8501 --no-autoupdate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ef3ead",
   "metadata": {},
   "source": [
    "## Next Steps (Future Work)\n",
    "\n",
    "After implementing and evaluating the Bi-LSTM model for fake news detection, the next stage is to explore more advanced architectures, especially transformer-based models. The planned next steps are:\n",
    "\n",
    "**1. Implement Transformer-based Models**\n",
    "* Train and fine-tune BERT (Bidirectional Encoder Representations from Transformers).\n",
    "* Experiment with lighter variants like DistilBERT for faster inference.\n",
    "* Explore domain-specific models such as RoBERTa or ALBERT.\n",
    "\n",
    "**2. Compare Performance**\n",
    "* Evaluate BERT models against the Bi-LSTM model on:\n",
    "  - accuracy\n",
    "  - F1-score\n",
    "  - inference time\n",
    "  - robustness on unseen data\n",
    "\n",
    "**3. Use Transfer Learning**\n",
    "* Leverage pretrained transformer checkpoints from HuggingFace.\n",
    "* Fine-tune on the fake-news dataset for improved contextual understanding.\n",
    "\n",
    "**4. Add Ensemble Approaches**\n",
    "* Combine predictions from LSTM, BERT, and classical models (LR, XGBoost).\n",
    "* Use stacking or weighted averaging to improve reliability.\n",
    "\n",
    "**5. Deploy the Improved Model**\n",
    "* Update the current Streamlit app with a BERT option.\n",
    "* Optimize model size for real-time inference."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
